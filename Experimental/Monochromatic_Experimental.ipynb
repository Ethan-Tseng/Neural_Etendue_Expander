{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01f63883",
   "metadata": {},
   "source": [
    "# Monochromatic Neural Étendue Expansion Experimental Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac28b847",
   "metadata": {},
   "source": [
    "### This notebook can be used to produce the monochromatic étendue expanded experimental holograms shown in the manuscript and in the supplementary information.\n",
    "\n",
    "### In the cells below please select one expander type and one target image. For example, to produce a 64x étendue expanded hologram with the neural étendue expander please select 'neural_mono_64x'. To produce a 16x étendue expanded hologram with a random expander [Kuo et al. 2020] please select 'random_16x'. To produce a conventional hologram [Shi et al. 2021] please select 'conventional_16x' or 'conventional_64x'. The target images provided are labeled as '000.png', '001.png', and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef8193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from imageio import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908f9ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- BEGIN CONFIG --- ###\n",
    "# Choose only one of the following expanders.\n",
    "#expander_type = 'conventional_16x'\n",
    "#expander_type = 'conventional_64x'\n",
    "#expander_type = 'random_16x'\n",
    "#expander_type = 'random_64x'\n",
    "#expander_type = 'neural_mono_16x'\n",
    "expander_type = 'neural_mono_64x'\n",
    "\n",
    "# Choose only one of the following target images.\n",
    "#target_img_name = '000'\n",
    "target_img_name = '001'\n",
    "### ---   END CONFIG --- ###\n",
    "\n",
    "if (expander_type == 'random_16x') or (expander_type == 'neural_mono_16x'):\n",
    "    correction_factor = np.array([1.0])\n",
    "    top_percentile = 99.9\n",
    "    eff_corners = None\n",
    "elif (expander_type == 'conventional_16x'):\n",
    "    correction_factor = np.array([1.0])\n",
    "    top_percentile = 99.9\n",
    "    eff_corners = [144,144,240,240]\n",
    "elif (expander_type == 'random_64x') or (expander_type == 'neural_mono_64x'):\n",
    "    correction_factor = np.array([1.0])\n",
    "    top_percentile = 99.0\n",
    "    eff_corners = None\n",
    "elif (expander_type == 'conventional_64x'):\n",
    "    correction_factor = np.array([1.0])\n",
    "    top_percentile = 99.9\n",
    "    eff_corners = [336,336,432,432]\n",
    "else:\n",
    "    assert('Undefined expander.')\n",
    "print(eff_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b94ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_img(img_name):\n",
    "    img = imread(img_name)\n",
    "    if img.dtype == 'uint8':\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "    elif img.dtype == 'uint16':\n",
    "        img = img.astype(np.float32) / 65535.0\n",
    "    elif img.dtype == 'float32':\n",
    "        img = img / 1.0\n",
    "    else:\n",
    "        assert('Invalid image type')\n",
    "    if len(img.shape) == 3:\n",
    "        img = 0.299 * img[:,:,0] + 0.587 * img[:,:,1] + 0.114 * img[:,:,2] # Convert to gray scale\n",
    "    return img\n",
    "\n",
    "def white_balance(cap_img, target_img, correction_factor, top_percentile, eff_corners = None):\n",
    "    # Normalize so that max == 1.\n",
    "    # We are only adjusting the ratios between the colors, not the overall brightness.\n",
    "    if eff_corners == None:\n",
    "        scale_factors = np.mean(target_img, axis=(0,1)) / np.mean(cap_img, axis=(0,1))\n",
    "    else:\n",
    "        cap_img_eff = cap_img[eff_corners[0]:eff_corners[2],eff_corners[1]:eff_corners[3]]\n",
    "        scale_factors = np.mean(target_img, axis=(0,1)) / np.mean(cap_img_eff, axis=(0,1))\n",
    "\n",
    "    scale_factors = scale_factors / np.max(scale_factors)\n",
    "    cap_img = cap_img * scale_factors\n",
    "\n",
    "    # Additional manual color balancing.\n",
    "    cap_img = cap_img * correction_factor\n",
    "\n",
    "    # Scale overall brightness so that top percentile of pixels are clipped.\n",
    "    top_scale = np.percentile(cap_img, top_percentile)\n",
    "    cap_img = cap_img / top_scale\n",
    "    return np.clip(cap_img, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a8642c",
   "metadata": {},
   "source": [
    "### Display Intensity Scaled Experimentally Captured Hologram ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acda60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img = get_target_img(os.path.join('Target_Images',target_img_name+'.png'))\n",
    "w_cap = np.load(os.path.join('Data',expander_type,'w',target_img_name+'.npy'))\n",
    "w_cap_wb = np.fliplr(white_balance(w_cap, target_img, correction_factor, top_percentile, eff_corners))\n",
    "w_cap_wb = np.stack([w_cap_wb, w_cap_wb, w_cap_wb], axis=-1)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Experimentally Captured Hologram')\n",
    "plt.imshow(w_cap_wb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc758bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
